{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes e Otimização de Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = join(dirname('__file__'), '.env')\n",
    "\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "ROOT_PATH = os.environ.get(\"ROOT_PATH\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(f\"{ROOT_PATH}/features/features.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo Classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (cross_val_predict, KFold, cross_val_score)\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, auc, roc_curve, plot_confusion_matrix, classification_report, accuracy_score)\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_estimators(model, params, x, y):\n",
    "    clf = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1, cv=5)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(m):\n",
    "    g1 = sns.heatmap(m, annot=True, cmap=\"YlGnBu\")\n",
    "    g1.set_xlabel('Predicted labels')\n",
    "    g1.set_ylabel('True labels')\n",
    "    g1.set_title('Confusion Matrix')\n",
    "\n",
    "\n",
    "def norm_confusion_matrix(y, y_pred):\n",
    "    m = confusion_matrix(y, y_pred)\n",
    "    return m.astype('float')/m.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "def svm(params: dict, x: np.ndarray, y: np.ndarray):\n",
    "    model = SVC()\n",
    "    clf = GridSearchCV(estimator=model, param_grid=params, n_jobs=-1)\n",
    "    clf.fit(x, y)\n",
    "    return clf\n",
    "\n",
    "    # cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    # model = SVC(kernel='rbf', probability=True, C=100, gamma=0.00001)\n",
    "    # scores = cross_val_score(model, x, y, scoring=[\n",
    "    #  'accuracy'], cv=cv, n_jobs=-1)\n",
    "    # print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "    # y_pred = cross_val_predict(model, x, y, cv=10)\n",
    "    # print(accuracy_score(y_true=y,y_pred=y_pred))\n",
    "    # print(classification_report(y_true=y,y_pred=y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificações Gerais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (train_test_split, KFold)\n",
    "\n",
    "x = df.loc[:, ['var', 'skew', 'kur']]\n",
    "y = df.loc[:, 'label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "\n",
    "param_svm = [{\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'gamma': [0.01, 0.001, 0.0001, 0.00001],\n",
    "    'kernel': ['rbf']\n",
    "}]\n",
    "\n",
    "\n",
    "param_knn = [{\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'algorithm':['ball_tree', 'kd_tree', 'brute']\n",
    "}]\n",
    "\n",
    "\n",
    "param_tree = [{\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth':np.arange(1, 7)\n",
    "}]\n",
    "\n",
    "result_svm = get_estimators(model=SVC(), params=param_svm, x=X_train, y=y_train)\n",
    "result_knn = get_estimators(model=KNN(), params=param_knn, x=X_train, y=y_train)\n",
    "result_tree = get_estimators(model=DTC(), params=param_tree, x=X_train, y=y_train)\n",
    "result_qda = get_estimators(model=QDA(), params={}, x=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DTC': {'criterion': 'gini', 'max_depth': 1, 'splitter': 'best'},\n",
      " 'KNN': {'algorithm': 'ball_tree', 'n_neighbors': 3},\n",
      " 'QDA': {},\n",
      " 'SVM': {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "best_params = {\n",
    "    'SVM': result_svm.cv_results_['params'][0],\n",
    "    'KNN': result_knn.cv_results_['params'][0],\n",
    "    'DTC': result_tree.cv_results_['params'][0],\n",
    "    'QDA': result_qda.cv_results_['params'][0]\n",
    "}\n",
    "\n",
    "pprint(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ictal       1.00      1.00      1.00       196\n",
      "      normal       1.00      1.00      1.00       183\n",
      "         pos       1.00      1.00      1.00        67\n",
      "         pre       1.00      1.00      1.00        50\n",
      "         rep       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       710\n",
      "   macro avg       1.00      1.00      1.00       710\n",
      "weighted avg       1.00      1.00      1.00       710\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ictal       1.00      1.00      1.00       196\n",
      "      normal       1.00      1.00      1.00       183\n",
      "         pos       1.00      1.00      1.00        67\n",
      "         pre       1.00      1.00      1.00        50\n",
      "         rep       1.00      1.00      1.00       214\n",
      "\n",
      "    accuracy                           1.00       710\n",
      "   macro avg       1.00      1.00      1.00       710\n",
      "weighted avg       1.00      1.00      1.00       710\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ictal       0.87      0.72      0.79       196\n",
      "      normal       0.55      1.00      0.71       183\n",
      "         pos       0.83      0.82      0.83        67\n",
      "         pre       0.76      0.78      0.77        50\n",
      "         rep       1.00      0.47      0.64       214\n",
      "\n",
      "    accuracy                           0.73       710\n",
      "   macro avg       0.80      0.76      0.75       710\n",
      "weighted avg       0.82      0.73      0.73       710\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ictal       0.67      0.37      0.48       196\n",
      "      normal       0.35      0.73      0.47       183\n",
      "         pos       0.39      0.39      0.39        67\n",
      "         pre       0.38      0.36      0.37        50\n",
      "         rep       0.14      0.07      0.09       214\n",
      "\n",
      "    accuracy                           0.37       710\n",
      "   macro avg       0.38      0.38      0.36       710\n",
      "weighted avg       0.38      0.37      0.34       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "print(classification_report(y_test, result_knn.best_estimator_.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, result_svm.best_estimator_.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, result_tree.best_estimator_.predict(X_test)))\n",
    "\n",
    "print(classification_report(y_test, result_qda.best_estimator_.predict(X_test)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "676d897f427d94a86f2cc2ce6d393a432491b28b1655c15eb47ad7d90dd20eb2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('siena_eeg_ecg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
